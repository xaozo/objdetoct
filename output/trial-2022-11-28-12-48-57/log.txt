[11/28 12:48:57] detectron2 INFO: Rank of current process: 0. World size: 1
[11/28 12:48:57] detectron2 INFO: Environment info:
----------------------  -----------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.10.8 (main, Nov  4 2022, 13:48:29) [GCC 11.2.0]
numpy                   1.23.4
detectron2              0.6 @/home/general/detectron2/detectron2
Compiler                GCC 9.4
CUDA compiler           not available
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.13.0+cu117 @/home/general/miniconda3/envs/test/lib/python3.10/site-packages/torch
PyTorch debug build     False
GPU available           Yes
GPU 0                   NVIDIA GeForce RTX 3090 (arch=8.6)
Driver version          526.98
CUDA_HOME               /usr
Pillow                  9.3.0
torchvision             0.14.0+cu117 @/home/general/miniconda3/envs/test/lib/python3.10/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.5.post20220512
iopath                  0.1.9
cv2                     4.6.0
----------------------  -----------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.6.0 (Git Hash 52b5f107dd9cf10910aaa19cb47f3abf9b349815)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.7
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.5
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.7, CUDNN_VERSION=8.5.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.13.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[11/28 12:48:57] detectron2 INFO: Command line arguments: Namespace(config_file='./configs/Detection/faster_rcnn_R_50_FPN_3x.yaml', resume=False, eval_only=False, num_gpus=1, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:50152', opts=[])
[11/28 12:48:57] detectron2 INFO: Contents of args.config_file=./configs/Detection/faster_rcnn_R_50_FPN_3x.yaml:
[38;5;197m_BASE_[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186m../Base-RCNN-FPN.yaml[39m[38;5;186m"[39m
[38;5;197mMODEL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mWEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mdetectron2://ImageNetPretrained/MSRA/R-50.pkl[39m[38;5;186m"[39m
[38;5;15m  [39m[38;5;197mMASK_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mFalse[39m
[38;5;15m  [39m[38;5;197mRESNETS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mDEPTH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m50[39m
[38;5;197mSOLVER[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mSTEPS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m(210000,[39m[38;5;141m [39m[38;5;141m250000)[39m
[38;5;15m  [39m[38;5;197mMAX_ITER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m270000[39m

[11/28 12:48:57] detectron2 INFO: Running with full config:
[38;5;197mCUDNN_BENCHMARK[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;197mDATALOADER[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mASPECT_RATIO_GROUPING[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m  [39m[38;5;197mFILTER_EMPTY_ANNOTATIONS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m  [39m[38;5;197mNUM_WORKERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m  [39m[38;5;197mREPEAT_THRESHOLD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;197mSAMPLER_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrainingSampler[39m
[38;5;197mDATASETS[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mPRECOMPUTED_PROPOSAL_TOPK_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m  [39m[38;5;197mPRECOMPUTED_PROPOSAL_TOPK_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2000[39m
[38;5;15m  [39m[38;5;197mPROPOSAL_FILES_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;197mPROPOSAL_FILES_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;197mTEST[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mval[39m
[38;5;15m  [39m[38;5;197mTRAIN[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mtrain[39m
[38;5;197mGLOBAL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mHACK[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;197mINPUT[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mCROP[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mSIZE[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.9[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.9[39m
[38;5;15m    [39m[38;5;197mTYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mrelative_range[39m
[38;5;15m  [39m[38;5;197mFORMAT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mBGR[39m
[38;5;15m  [39m[38;5;197mMASK_FORMAT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mpolygon[39m
[38;5;15m  [39m[38;5;197mMAX_SIZE_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1333[39m
[38;5;15m  [39m[38;5;197mMAX_SIZE_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1333[39m
[38;5;15m  [39m[38;5;197mMIN_SIZE_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m800[39m
[38;5;15m  [39m[38;5;197mMIN_SIZE_TRAIN[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m640[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m672[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m704[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m736[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m768[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m800[39m
[38;5;15m  [39m[38;5;197mMIN_SIZE_TRAIN_SAMPLING[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mchoice[39m
[38;5;15m  [39m[38;5;197mRANDOM_FLIP[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mhorizontal[39m
[38;5;197mMODEL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mANCHOR_GENERATOR[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mANGLES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-90[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m90[39m
[38;5;15m    [39m[38;5;197mASPECT_RATIOS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mDefaultAnchorGenerator[39m
[38;5;15m    [39m[38;5;197mOFFSET[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mSIZES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m32[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m64[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m128[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m  [39m[38;5;197mBACKBONE[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mFREEZE_AT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mbuild_resnet_fpn_backbone[39m
[38;5;15m  [39m[38;5;197mDEVICE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mcuda[39m
[38;5;15m  [39m[38;5;197mFPN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mFUSE_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msum[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres5[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mOUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m  [39m[38;5;197mKEYPOINT_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mLOAD_PROPOSALS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mMASK_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mMETA_ARCHITECTURE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mGeneralizedRCNN[39m
[38;5;15m  [39m[38;5;197mPANOPTIC_FPN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCOMBINE[39m[38;5;15m:[39m
[38;5;15m      [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m      [39m[38;5;197mINSTANCES_CONFIDENCE_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m      [39m[38;5;197mOVERLAP_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m      [39m[38;5;197mSTUFF_AREA_LIMIT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4096[39m
[38;5;15m    [39m[38;5;197mINSTANCE_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m  [39m[38;5;197mPIXEL_MEAN[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m103.53[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m116.28[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m123.675[39m
[38;5;15m  [39m[38;5;197mPIXEL_STD[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m  [39m[38;5;197mPROPOSAL_GENERATOR[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mMIN_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mRPN[39m
[38;5;15m  [39m[38;5;197mRESNETS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mDEFORM_MODULATED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mDEFORM_NUM_GROUPS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mDEFORM_ON_PER_STAGE[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mDEPTH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m50[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mFrozenBN[39m
[38;5;15m    [39m[38;5;197mNUM_GROUPS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mOUT_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mres5[39m
[38;5;15m    [39m[38;5;197mRES2_OUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mRES5_DILATION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mSTEM_OUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m64[39m
[38;5;15m    [39m[38;5;197mSTRIDE_IN_1X1[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mWIDTH_PER_GROUP[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m64[39m
[38;5;15m  [39m[38;5;197mRETINANET[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msmooth_l1[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m&id002[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mFOCAL_LOSS_ALPHA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.25[39m
[38;5;15m    [39m[38;5;197mFOCAL_LOSS_GAMMA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp5[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp7[39m
[38;5;15m    [39m[38;5;197mIOU_LABELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mIOU_THRESHOLDS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mNMS_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m3[39m
[38;5;15m    [39m[38;5;197mNUM_CONVS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;197mPRIOR_PROB[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.01[39m
[38;5;15m    [39m[38;5;197mSCORE_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.05[39m
[38;5;15m    [39m[38;5;197mSMOOTH_L1_LOSS_BETA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m    [39m[38;5;197mTOPK_CANDIDATES_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m  [39m[38;5;197mROI_BOX_CASCADE_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m&id001[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m5.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m5.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m20.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m20.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m30.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m30.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m15.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m15.0[39m
[38;5;15m    [39m[38;5;197mIOUS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.7[39m
[38;5;15m  [39m[38;5;197mROI_BOX_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msmooth_l1[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m*id001[39m
[38;5;15m    [39m[38;5;197mCLS_AGNOSTIC_BBOX_REG[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mCONV_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mFC_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1024[39m
[38;5;15m    [39m[38;5;197mFED_LOSS_FREQ_WEIGHT_POWER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mFED_LOSS_NUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m50[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mFastRCNNConvFCHead[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mNUM_CONV[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mNUM_FC[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;15m    [39m[38;5;197mPOOLER_RESOLUTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m7[39m
[38;5;15m    [39m[38;5;197mPOOLER_SAMPLING_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPOOLER_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mROIAlignV2[39m
[38;5;15m    [39m[38;5;197mSMOOTH_L1_BETA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;197mTRAIN_ON_PRED_BOXES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mUSE_FED_LOSS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mUSE_SIGMOID_CE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mROI_HEADS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBATCH_SIZE_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp5[39m
[38;5;15m    [39m[38;5;197mIOU_LABELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mIOU_THRESHOLDS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mStandardROIHeads[39m
[38;5;15m    [39m[38;5;197mNMS_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m3[39m
[38;5;15m    [39m[38;5;197mPOSITIVE_FRACTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.25[39m
[38;5;15m    [39m[38;5;197mPROPOSAL_APPEND_GT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mSCORE_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.05[39m
[38;5;15m  [39m[38;5;197mROI_HEADS_BATCH_SIZE_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m64[39m
[38;5;15m  [39m[38;5;197mROI_KEYPOINT_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCONV_DIMS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;197mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mMIN_KEYPOINTS_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mKRCNNConvDeconvUpsampleHead[39m
[38;5;15m    [39m[38;5;197mNORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mNUM_KEYPOINTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m17[39m
[38;5;15m    [39m[38;5;197mPOOLER_RESOLUTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m14[39m
[38;5;15m    [39m[38;5;197mPOOLER_SAMPLING_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPOOLER_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mROIAlignV2[39m
[38;5;15m  [39m[38;5;197mROI_MASK_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCLS_AGNOSTIC_MASK[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mCONV_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mMaskRCNNConvUpsampleHead[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mNUM_CONV[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;197mPOOLER_RESOLUTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m14[39m
[38;5;15m    [39m[38;5;197mPOOLER_SAMPLING_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;197mPOOLER_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mROIAlignV2[39m
[38;5;15m  [39m[38;5;197mRPN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBATCH_SIZE_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msmooth_l1[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m*id002[39m
[38;5;15m    [39m[38;5;197mBOUNDARY_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;197mCONV_DIMS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;197mHEAD_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mStandardRPNHead[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp5[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp6[39m
[38;5;15m    [39m[38;5;197mIOU_LABELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;197mIOU_THRESHOLDS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.7[39m
[38;5;15m    [39m[38;5;197mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mNMS_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.7[39m
[38;5;15m    [39m[38;5;197mPOSITIVE_FRACTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;197mPOST_NMS_TOPK_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m    [39m[38;5;197mPOST_NMS_TOPK_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m    [39m[38;5;197mPRE_NMS_TOPK_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m    [39m[38;5;197mPRE_NMS_TOPK_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2000[39m
[38;5;15m    [39m[38;5;197mSMOOTH_L1_BETA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;197mSEM_SEG_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCOMMON_STRIDE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;197mCONVS_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m128[39m
[38;5;15m    [39m[38;5;197mIGNORE_VALUE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m255[39m
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp5[39m
[38;5;15m    [39m[38;5;197mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mSemSegFPNHead[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mGN[39m
[38;5;15m    [39m[38;5;197mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m54[39m
[38;5;15m  [39m[38;5;197mWEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mdetectron2://ImageNetPretrained/MSRA/R-50.pkl[39m
[38;5;197mOUTPUT_DIR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m./output/trial-2022-11-28-12-48-57[39m
[38;5;197mSEED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;197mSOLVER[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mAMP[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mBASE_LR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0001[39m
[38;5;15m  [39m[38;5;197mBASE_LR_END[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;197mBIAS_LR_FACTOR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m  [39m[38;5;197mCHECKPOINT_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m5000[39m
[38;5;15m  [39m[38;5;197mCLIP_GRADIENTS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCLIP_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mvalue[39m
[38;5;15m    [39m[38;5;197mCLIP_VALUE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mNORM_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m  [39m[38;5;197mGAMMA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m  [39m[38;5;197mIMS_PER_BATCH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m16[39m
[38;5;15m  [39m[38;5;197mLR_SCHEDULER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mWarmupMultiStepLR[39m
[38;5;15m  [39m[38;5;197mMAX_ITER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m320[39m
[38;5;15m  [39m[38;5;197mMOMENTUM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.9[39m
[38;5;15m  [39m[38;5;197mNESTEROV[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mNUM_DECAYS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m3[39m
[38;5;15m  [39m[38;5;197mREFERENCE_WORLD_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m  [39m[38;5;197mRESCALE_INTERVAL[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;197mSTEPS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;197mWARMUP_FACTOR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.001[39m
[38;5;15m  [39m[38;5;197mWARMUP_ITERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m  [39m[38;5;197mWARMUP_METHOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mlinear[39m
[38;5;15m  [39m[38;5;197mWEIGHT_DECAY[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0001[39m
[38;5;15m  [39m[38;5;197mWEIGHT_DECAY_BIAS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mnull[39m
[38;5;15m  [39m[38;5;197mWEIGHT_DECAY_NORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;197mTEST[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mAUG[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mFLIP[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;197mMAX_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4000[39m
[38;5;15m    [39m[38;5;197mMIN_SIZES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m400[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m500[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m600[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m700[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m800[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m900[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1100[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1200[39m
[38;5;15m  [39m[38;5;197mDETECTIONS_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m100[39m
[38;5;15m  [39m[38;5;197mEVAL_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m16[39m
[38;5;15m  [39m[38;5;197mEXPECTED_RESULTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;197mKEYPOINT_OKS_SIGMAS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;197mPRECISE_BN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;197mNUM_ITER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m200[39m
[38;5;197mVERSION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;197mVIS_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m

[11/28 12:48:57] detectron2 INFO: Full config saved to ./output/trial-2022-11-28-12-48-57/config.yaml
[11/28 12:48:57] d2.utils.env INFO: Using a generated random seed 57428040
[11/28 12:48:57] d2.engine.defaults INFO: Model:
GeneralizedRCNN(
  (backbone): FPN(
    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (top_block): LastLevelMaxPool()
    (bottom_up): ResNet(
      (stem): BasicStem(
        (conv1): Conv2d(
          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
      )
      (res2): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv1): Conv2d(
            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
      )
      (res3): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv1): Conv2d(
            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
      )
      (res4): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv1): Conv2d(
            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (4): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (5): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
      )
      (res5): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv1): Conv2d(
            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
      )
    )
  )
  (proposal_generator): RPN(
    (rpn_head): StandardRPNHead(
      (conv): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
        (activation): ReLU()
      )
      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))
    )
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
  )
  (roi_heads): StandardROIHeads(
    (box_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)
        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)
        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)
      )
    )
    (box_head): FastRCNNConvFCHead(
      (flatten): Flatten(start_dim=1, end_dim=-1)
      (fc1): Linear(in_features=12544, out_features=1024, bias=True)
      (fc_relu1): ReLU()
      (fc2): Linear(in_features=1024, out_features=1024, bias=True)
      (fc_relu2): ReLU()
    )
    (box_predictor): FastRCNNOutputLayers(
      (cls_score): Linear(in_features=1024, out_features=4, bias=True)
      (bbox_pred): Linear(in_features=1024, out_features=12, bias=True)
    )
  )
)
[11/28 12:48:57] d2.data.datasets.coco WARNING: 
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[11/28 12:48:57] d2.data.datasets.coco INFO: Loaded 565 images in COCO format from ./dataset/train/labels_train.json
[11/28 12:48:57] d2.data.build INFO: Removed 0 images with no usable annotations. 565 images left.
[11/28 12:48:57] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]
[11/28 12:48:57] d2.data.build INFO: Using training sampler TrainingSampler
[11/28 12:48:57] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common.NumpySerializedList'>
[11/28 12:48:57] d2.data.common INFO: Serializing 565 elements to byte tensors and concatenating them all ...
[11/28 12:48:57] d2.data.common INFO: Serialized dataset takes 0.21 MiB
[11/28 12:48:57] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]
[11/28 12:48:57] d2.data.datasets.coco WARNING: 
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[11/28 12:48:57] d2.data.datasets.coco INFO: Loaded 184 images in COCO format from ./dataset/val/labels_val.json
[11/28 12:48:57] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common.NumpySerializedList'>
[11/28 12:48:57] d2.data.common INFO: Serializing 184 elements to byte tensors and concatenating them all ...
[11/28 12:48:57] d2.data.common INFO: Serialized dataset takes 0.07 MiB
[11/28 12:48:57] fvcore.common.checkpoint INFO: [Checkpointer] Loading from detectron2://ImageNetPretrained/MSRA/R-50.pkl ...
[11/28 12:48:57] d2.checkpoint.c2_model_loading INFO: Renaming Caffe2 weights ......
[11/28 12:48:58] d2.checkpoint.c2_model_loading INFO: Following weights matched with submodule backbone.bottom_up:
| Names in Model    | Names in Checkpoint      | Shapes                                          |
|:------------------|:-------------------------|:------------------------------------------------|
| res2.0.conv1.*    | res2_0_branch2a_{bn_*,w} | (64,) (64,) (64,) (64,) (64,64,1,1)             |
| res2.0.conv2.*    | res2_0_branch2b_{bn_*,w} | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.0.conv3.*    | res2_0_branch2c_{bn_*,w} | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.0.shortcut.* | res2_0_branch1_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.1.conv1.*    | res2_1_branch2a_{bn_*,w} | (64,) (64,) (64,) (64,) (64,256,1,1)            |
| res2.1.conv2.*    | res2_1_branch2b_{bn_*,w} | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.1.conv3.*    | res2_1_branch2c_{bn_*,w} | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.2.conv1.*    | res2_2_branch2a_{bn_*,w} | (64,) (64,) (64,) (64,) (64,256,1,1)            |
| res2.2.conv2.*    | res2_2_branch2b_{bn_*,w} | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.2.conv3.*    | res2_2_branch2c_{bn_*,w} | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res3.0.conv1.*    | res3_0_branch2a_{bn_*,w} | (128,) (128,) (128,) (128,) (128,256,1,1)       |
| res3.0.conv2.*    | res3_0_branch2b_{bn_*,w} | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.0.conv3.*    | res3_0_branch2c_{bn_*,w} | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.0.shortcut.* | res3_0_branch1_{bn_*,w}  | (512,) (512,) (512,) (512,) (512,256,1,1)       |
| res3.1.conv1.*    | res3_1_branch2a_{bn_*,w} | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.1.conv2.*    | res3_1_branch2b_{bn_*,w} | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.1.conv3.*    | res3_1_branch2c_{bn_*,w} | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.2.conv1.*    | res3_2_branch2a_{bn_*,w} | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.2.conv2.*    | res3_2_branch2b_{bn_*,w} | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.2.conv3.*    | res3_2_branch2c_{bn_*,w} | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.3.conv1.*    | res3_3_branch2a_{bn_*,w} | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.3.conv2.*    | res3_3_branch2b_{bn_*,w} | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.3.conv3.*    | res3_3_branch2c_{bn_*,w} | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res4.0.conv1.*    | res4_0_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,512,1,1)       |
| res4.0.conv2.*    | res4_0_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.0.conv3.*    | res4_0_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.0.shortcut.* | res4_0_branch1_{bn_*,w}  | (1024,) (1024,) (1024,) (1024,) (1024,512,1,1)  |
| res4.1.conv1.*    | res4_1_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.1.conv2.*    | res4_1_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.1.conv3.*    | res4_1_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.2.conv1.*    | res4_2_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.2.conv2.*    | res4_2_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.2.conv3.*    | res4_2_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.3.conv1.*    | res4_3_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.3.conv2.*    | res4_3_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.3.conv3.*    | res4_3_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.4.conv1.*    | res4_4_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.4.conv2.*    | res4_4_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.4.conv3.*    | res4_4_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.5.conv1.*    | res4_5_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.5.conv2.*    | res4_5_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.5.conv3.*    | res4_5_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res5.0.conv1.*    | res5_0_branch2a_{bn_*,w} | (512,) (512,) (512,) (512,) (512,1024,1,1)      |
| res5.0.conv2.*    | res5_0_branch2b_{bn_*,w} | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.0.conv3.*    | res5_0_branch2c_{bn_*,w} | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| res5.0.shortcut.* | res5_0_branch1_{bn_*,w}  | (2048,) (2048,) (2048,) (2048,) (2048,1024,1,1) |
| res5.1.conv1.*    | res5_1_branch2a_{bn_*,w} | (512,) (512,) (512,) (512,) (512,2048,1,1)      |
| res5.1.conv2.*    | res5_1_branch2b_{bn_*,w} | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.1.conv3.*    | res5_1_branch2c_{bn_*,w} | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| res5.2.conv1.*    | res5_2_branch2a_{bn_*,w} | (512,) (512,) (512,) (512,) (512,2048,1,1)      |
| res5.2.conv2.*    | res5_2_branch2b_{bn_*,w} | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.2.conv3.*    | res5_2_branch2c_{bn_*,w} | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| stem.conv1.norm.* | res_conv1_bn_*           | (64,) (64,) (64,) (64,)                         |
| stem.conv1.weight | conv1_w                  | (64, 3, 7, 7)                                   |
[11/28 12:48:58] fvcore.common.checkpoint WARNING: Some model parameters or buffers are not found in the checkpoint:
backbone.fpn_lateral2.{bias, weight}
backbone.fpn_lateral3.{bias, weight}
backbone.fpn_lateral4.{bias, weight}
backbone.fpn_lateral5.{bias, weight}
backbone.fpn_output2.{bias, weight}
backbone.fpn_output3.{bias, weight}
backbone.fpn_output4.{bias, weight}
backbone.fpn_output5.{bias, weight}
proposal_generator.rpn_head.anchor_deltas.{bias, weight}
proposal_generator.rpn_head.conv.{bias, weight}
proposal_generator.rpn_head.objectness_logits.{bias, weight}
roi_heads.box_head.fc1.{bias, weight}
roi_heads.box_head.fc2.{bias, weight}
roi_heads.box_predictor.bbox_pred.{bias, weight}
roi_heads.box_predictor.cls_score.{bias, weight}
[11/28 12:48:58] fvcore.common.checkpoint WARNING: The checkpoint state_dict contains keys that are not used by the model:
  fc1000.{bias, weight}
  stem.conv1.bias
[11/28 12:48:58] d2.engine.train_loop INFO: Starting training from iteration 0
[11/28 12:49:11] d2.data.datasets.coco WARNING: 
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[11/28 12:49:11] d2.data.datasets.coco INFO: Loaded 184 images in COCO format from ./dataset/val/labels_val.json
[11/28 12:49:11] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[11/28 12:49:11] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common.NumpySerializedList'>
[11/28 12:49:11] d2.data.common INFO: Serializing 184 elements to byte tensors and concatenating them all ...
[11/28 12:49:11] d2.data.common INFO: Serialized dataset takes 0.07 MiB
[11/28 12:49:11] d2.evaluation.coco_evaluation WARNING: COCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.
[11/28 12:49:11] d2.evaluation.evaluator INFO: Start inference on 184 batches
[11/28 12:49:12] d2.evaluation.evaluator INFO: Inference done 11/184. Dataloading: 0.0006 s/iter. Inference: 0.0316 s/iter. Eval: 0.0005 s/iter. Total: 0.0327 s/iter. ETA=0:00:05
[11/28 12:49:17] d2.evaluation.evaluator INFO: Inference done 163/184. Dataloading: 0.0008 s/iter. Inference: 0.0316 s/iter. Eval: 0.0005 s/iter. Total: 0.0330 s/iter. ETA=0:00:00
[11/28 12:49:18] d2.evaluation.evaluator INFO: Total inference time: 0:00:05.915032 (0.033045 s / iter per device, on 1 devices)
[11/28 12:49:18] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:00:05 (0.031497 s / iter per device, on 1 devices)
[11/28 12:49:18] d2.evaluation.coco_evaluation INFO: Preparing results for COCO format ...
[11/28 12:49:18] d2.evaluation.coco_evaluation INFO: Saving results to ./output/trial-2022-11-28-12-48-57/inference/coco_instances_results.json
[11/28 12:49:18] d2.evaluation.coco_evaluation INFO: Evaluating predictions with unofficial COCO API...
[11/28 12:49:18] d2.evaluation.fast_eval_api INFO: Evaluate annotation type *bbox*
[11/28 12:49:18] d2.evaluation.fast_eval_api INFO: COCOeval_opt.evaluate() finished in 0.08 seconds.
[11/28 12:49:18] d2.evaluation.fast_eval_api INFO: Accumulating evaluation results...
[11/28 12:49:18] d2.evaluation.fast_eval_api INFO: COCOeval_opt.accumulate() finished in 0.02 seconds.
[11/28 12:49:18] d2.evaluation.coco_evaluation INFO: Evaluation results for bbox: 
|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |
|:-----:|:------:|:------:|:-----:|:-----:|:-----:|
| 0.008 | 0.015  | 0.014  | 0.000 | 0.036 | 0.012 |
[11/28 12:49:18] d2.evaluation.coco_evaluation INFO: Per-category bbox AP: 
| category   | AP    | category   | AP    | category   | AP    |
|:-----------|:------|:-----------|:------|:-----------|:------|
| break      | 0.000 | disc       | 0.000 | shadow     | 0.025 |
[11/28 12:49:18] d2.engine.defaults INFO: Evaluation results for val in csv format:
[11/28 12:49:18] d2.evaluation.testing INFO: copypaste: Task: bbox
[11/28 12:49:18] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[11/28 12:49:18] d2.evaluation.testing INFO: copypaste: 0.0083,0.0146,0.0138,0.0000,0.0360,0.0119
[11/28 12:49:29] d2.utils.events INFO:  eta: 0:04:10  iter: 19  total_loss: 2.83  loss_cls: 1.319  loss_box_reg: 0.008615  loss_rpn_cls: 0.7125  loss_rpn_loc: 0.8199  validation_loss: 2.821  time: 0.8286  data_time: 0.0635  lr: 6.0316e-06  max_mem: 10279M
[11/28 12:49:39] d2.data.datasets.coco WARNING: 
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[11/28 12:49:39] d2.data.datasets.coco INFO: Loaded 184 images in COCO format from ./dataset/val/labels_val.json
[11/28 12:49:39] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[11/28 12:49:39] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common.NumpySerializedList'>
[11/28 12:49:39] d2.data.common INFO: Serializing 184 elements to byte tensors and concatenating them all ...
[11/28 12:49:39] d2.data.common INFO: Serialized dataset takes 0.07 MiB
[11/28 12:49:39] d2.evaluation.coco_evaluation WARNING: COCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.
[11/28 12:49:39] d2.evaluation.evaluator INFO: Start inference on 184 batches
[11/28 12:49:40] d2.evaluation.evaluator INFO: Inference done 11/184. Dataloading: 0.0006 s/iter. Inference: 0.0320 s/iter. Eval: 0.0005 s/iter. Total: 0.0331 s/iter. ETA=0:00:05
[11/28 12:49:45] d2.evaluation.evaluator INFO: Inference done 161/184. Dataloading: 0.0008 s/iter. Inference: 0.0320 s/iter. Eval: 0.0005 s/iter. Total: 0.0334 s/iter. ETA=0:00:00
[11/28 12:49:46] d2.evaluation.evaluator INFO: Total inference time: 0:00:05.981681 (0.033417 s / iter per device, on 1 devices)
[11/28 12:49:46] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:00:05 (0.031881 s / iter per device, on 1 devices)
[11/28 12:49:46] d2.evaluation.coco_evaluation INFO: Preparing results for COCO format ...
[11/28 12:49:46] d2.evaluation.coco_evaluation INFO: Saving results to ./output/trial-2022-11-28-12-48-57/inference/coco_instances_results.json
[11/28 12:49:46] d2.evaluation.coco_evaluation INFO: Evaluating predictions with unofficial COCO API...
[11/28 12:49:46] d2.evaluation.fast_eval_api INFO: Evaluate annotation type *bbox*
[11/28 12:49:46] d2.evaluation.fast_eval_api INFO: COCOeval_opt.evaluate() finished in 0.07 seconds.
[11/28 12:49:46] d2.evaluation.fast_eval_api INFO: Accumulating evaluation results...
[11/28 12:49:46] d2.evaluation.fast_eval_api INFO: COCOeval_opt.accumulate() finished in 0.02 seconds.
[11/28 12:49:46] d2.evaluation.coco_evaluation INFO: Evaluation results for bbox: 
|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |
|:-----:|:------:|:------:|:-----:|:-----:|:-----:|
| 0.043 | 0.218  | 0.025  | 0.000 | 0.129 | 0.033 |
[11/28 12:49:46] d2.evaluation.coco_evaluation INFO: Per-category bbox AP: 
| category   | AP    | category   | AP    | category   | AP    |
|:-----------|:------|:-----------|:------|:-----------|:------|
| break      | 0.000 | disc       | 0.074 | shadow     | 0.054 |
[11/28 12:49:46] d2.engine.defaults INFO: Evaluation results for val in csv format:
[11/28 12:49:46] d2.evaluation.testing INFO: copypaste: Task: bbox
[11/28 12:49:46] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[11/28 12:49:46] d2.evaluation.testing INFO: copypaste: 0.0425,0.2185,0.0254,0.0000,0.1294,0.0326
[11/28 12:50:01] d2.utils.events INFO:  eta: 0:03:52  iter: 39  total_loss: 1.966  loss_cls: 0.3956  loss_box_reg: 0.008067  loss_rpn_cls: 0.7062  loss_rpn_loc: 0.8867  validation_loss: 2.465  time: 0.8247  data_time: 0.0528  lr: 1.2275e-05  max_mem: 10279M
[11/28 12:50:08] d2.data.datasets.coco WARNING: 
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[11/28 12:50:08] d2.data.datasets.coco INFO: Loaded 184 images in COCO format from ./dataset/val/labels_val.json
[11/28 12:50:08] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[11/28 12:50:08] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common.NumpySerializedList'>
[11/28 12:50:08] d2.data.common INFO: Serializing 184 elements to byte tensors and concatenating them all ...
[11/28 12:50:08] d2.data.common INFO: Serialized dataset takes 0.07 MiB
[11/28 12:50:08] d2.evaluation.coco_evaluation WARNING: COCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.
[11/28 12:50:08] d2.evaluation.evaluator INFO: Start inference on 184 batches
[11/28 12:50:08] d2.evaluation.evaluator INFO: Inference done 11/184. Dataloading: 0.0006 s/iter. Inference: 0.0320 s/iter. Eval: 0.0005 s/iter. Total: 0.0331 s/iter. ETA=0:00:05
[11/28 12:50:13] d2.evaluation.evaluator INFO: Inference done 162/184. Dataloading: 0.0009 s/iter. Inference: 0.0317 s/iter. Eval: 0.0005 s/iter. Total: 0.0331 s/iter. ETA=0:00:00
[11/28 12:50:14] d2.evaluation.evaluator INFO: Total inference time: 0:00:05.933308 (0.033147 s / iter per device, on 1 devices)
[11/28 12:50:14] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:00:05 (0.031550 s / iter per device, on 1 devices)
[11/28 12:50:14] d2.evaluation.coco_evaluation INFO: Preparing results for COCO format ...
[11/28 12:50:14] d2.evaluation.coco_evaluation INFO: Saving results to ./output/trial-2022-11-28-12-48-57/inference/coco_instances_results.json
[11/28 12:50:14] d2.evaluation.coco_evaluation INFO: Evaluating predictions with unofficial COCO API...
[11/28 12:50:14] d2.evaluation.fast_eval_api INFO: Evaluate annotation type *bbox*
[11/28 12:50:14] d2.evaluation.fast_eval_api INFO: COCOeval_opt.evaluate() finished in 0.09 seconds.
[11/28 12:50:14] d2.evaluation.fast_eval_api INFO: Accumulating evaluation results...
[11/28 12:50:14] d2.evaluation.fast_eval_api INFO: COCOeval_opt.accumulate() finished in 0.02 seconds.
[11/28 12:50:14] d2.evaluation.coco_evaluation INFO: Evaluation results for bbox: 
|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |
|:-----:|:------:|:------:|:-----:|:-----:|:-----:|
| 0.044 | 0.365  | 0.010  | 0.000 | 0.070 | 0.040 |
[11/28 12:50:14] d2.evaluation.coco_evaluation INFO: Per-category bbox AP: 
| category   | AP    | category   | AP    | category   | AP    |
|:-----------|:------|:-----------|:------|:-----------|:------|
| break      | 0.000 | disc       | 0.114 | shadow     | 0.019 |
[11/28 12:50:14] d2.engine.defaults INFO: Evaluation results for val in csv format:
[11/28 12:50:14] d2.evaluation.testing INFO: copypaste: Task: bbox
[11/28 12:50:14] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[11/28 12:50:14] d2.evaluation.testing INFO: copypaste: 0.0442,0.3652,0.0097,0.0000,0.0702,0.0405
[11/28 12:50:33] d2.utils.events INFO:  eta: 0:03:37  iter: 59  total_loss: 1.68  loss_cls: 0.08641  loss_box_reg: 0.006751  loss_rpn_cls: 0.693  loss_rpn_loc: 0.8717  validation_loss: 2.109  time: 0.8288  data_time: 0.0551  lr: 1.8519e-05  max_mem: 10279M
[11/28 12:50:36] d2.data.datasets.coco WARNING: 
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[11/28 12:50:36] d2.data.datasets.coco INFO: Loaded 184 images in COCO format from ./dataset/val/labels_val.json
[11/28 12:50:36] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[11/28 12:50:36] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common.NumpySerializedList'>
[11/28 12:50:36] d2.data.common INFO: Serializing 184 elements to byte tensors and concatenating them all ...
[11/28 12:50:36] d2.data.common INFO: Serialized dataset takes 0.07 MiB
[11/28 12:50:36] d2.evaluation.coco_evaluation WARNING: COCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.
[11/28 12:50:36] d2.evaluation.evaluator INFO: Start inference on 184 batches
[11/28 12:50:37] d2.evaluation.evaluator INFO: Inference done 11/184. Dataloading: 0.0007 s/iter. Inference: 0.0312 s/iter. Eval: 0.0004 s/iter. Total: 0.0324 s/iter. ETA=0:00:05
[11/28 12:50:42] d2.evaluation.evaluator INFO: Inference done 161/184. Dataloading: 0.0009 s/iter. Inference: 0.0320 s/iter. Eval: 0.0005 s/iter. Total: 0.0335 s/iter. ETA=0:00:00
[11/28 12:50:43] d2.evaluation.evaluator INFO: Total inference time: 0:00:06.000823 (0.033524 s / iter per device, on 1 devices)
[11/28 12:50:43] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:00:05 (0.031926 s / iter per device, on 1 devices)
[11/28 12:50:43] d2.evaluation.coco_evaluation INFO: Preparing results for COCO format ...
[11/28 12:50:43] d2.evaluation.coco_evaluation INFO: Saving results to ./output/trial-2022-11-28-12-48-57/inference/coco_instances_results.json
[11/28 12:50:43] d2.evaluation.coco_evaluation INFO: Evaluating predictions with unofficial COCO API...
[11/28 12:50:43] d2.evaluation.fast_eval_api INFO: Evaluate annotation type *bbox*
[11/28 12:50:43] d2.evaluation.fast_eval_api INFO: COCOeval_opt.evaluate() finished in 0.06 seconds.
[11/28 12:50:43] d2.evaluation.fast_eval_api INFO: Accumulating evaluation results...
[11/28 12:50:43] d2.evaluation.fast_eval_api INFO: COCOeval_opt.accumulate() finished in 0.02 seconds.
[11/28 12:50:43] d2.evaluation.coco_evaluation INFO: Evaluation results for bbox: 
|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |
|:-----:|:------:|:------:|:-----:|:-----:|:-----:|
| 0.017 | 0.130  | 0.004  | 0.000 | 0.058 | 0.016 |
[11/28 12:50:43] d2.evaluation.coco_evaluation INFO: Per-category bbox AP: 
| category   | AP    | category   | AP    | category   | AP    |
|:-----------|:------|:-----------|:------|:-----------|:------|
| break      | 0.000 | disc       | 0.043 | shadow     | 0.008 |
[11/28 12:50:43] d2.engine.defaults INFO: Evaluation results for val in csv format:
[11/28 12:50:43] d2.evaluation.testing INFO: copypaste: Task: bbox
[11/28 12:50:43] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[11/28 12:50:43] d2.evaluation.testing INFO: copypaste: 0.0169,0.1299,0.0035,0.0000,0.0582,0.0161
[11/28 12:51:05] d2.data.datasets.coco WARNING: 
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[11/28 12:51:05] d2.data.datasets.coco INFO: Loaded 184 images in COCO format from ./dataset/val/labels_val.json
[11/28 12:51:05] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[11/28 12:51:05] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common.NumpySerializedList'>
[11/28 12:51:05] d2.data.common INFO: Serializing 184 elements to byte tensors and concatenating them all ...
[11/28 12:51:05] d2.data.common INFO: Serialized dataset takes 0.07 MiB
[11/28 12:51:05] d2.evaluation.coco_evaluation WARNING: COCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.
[11/28 12:51:05] d2.evaluation.evaluator INFO: Start inference on 184 batches
[11/28 12:51:06] d2.evaluation.evaluator INFO: Inference done 11/184. Dataloading: 0.0007 s/iter. Inference: 0.0334 s/iter. Eval: 0.0006 s/iter. Total: 0.0347 s/iter. ETA=0:00:06
[11/28 12:51:11] d2.evaluation.evaluator INFO: Inference done 157/184. Dataloading: 0.0009 s/iter. Inference: 0.0318 s/iter. Eval: 0.0015 s/iter. Total: 0.0343 s/iter. ETA=0:00:00
[11/28 12:51:12] d2.evaluation.evaluator INFO: Total inference time: 0:00:06.126455 (0.034226 s / iter per device, on 1 devices)
[11/28 12:51:12] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:00:05 (0.031761 s / iter per device, on 1 devices)
[11/28 12:51:12] d2.evaluation.coco_evaluation INFO: Preparing results for COCO format ...
[11/28 12:51:12] d2.evaluation.coco_evaluation INFO: Saving results to ./output/trial-2022-11-28-12-48-57/inference/coco_instances_results.json
[11/28 12:51:12] d2.evaluation.coco_evaluation INFO: Evaluating predictions with unofficial COCO API...
[11/28 12:51:12] d2.evaluation.fast_eval_api INFO: Evaluate annotation type *bbox*
[11/28 12:51:12] d2.evaluation.fast_eval_api INFO: COCOeval_opt.evaluate() finished in 0.07 seconds.
[11/28 12:51:12] d2.evaluation.fast_eval_api INFO: Accumulating evaluation results...
[11/28 12:51:12] d2.evaluation.fast_eval_api INFO: COCOeval_opt.accumulate() finished in 0.02 seconds.
[11/28 12:51:12] d2.evaluation.coco_evaluation INFO: Evaluation results for bbox: 
|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |
|:-----:|:------:|:------:|:-----:|:-----:|:-----:|
| 0.006 | 0.047  | 0.000  | 0.000 | 0.022 | 0.006 |
[11/28 12:51:12] d2.evaluation.coco_evaluation INFO: Per-category bbox AP: 
| category   | AP    | category   | AP    | category   | AP    |
|:-----------|:------|:-----------|:------|:-----------|:------|
| break      | 0.000 | disc       | 0.016 | shadow     | 0.003 |
[11/28 12:51:12] d2.engine.defaults INFO: Evaluation results for val in csv format:
[11/28 12:51:12] d2.evaluation.testing INFO: copypaste: Task: bbox
[11/28 12:51:12] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[11/28 12:51:12] d2.evaluation.testing INFO: copypaste: 0.0064,0.0469,0.0000,0.0000,0.0215,0.0064
[11/28 12:51:20] d2.utils.events INFO:  eta: 0:03:21  iter: 79  total_loss: 1.627  loss_cls: 0.06156  loss_box_reg: 0.005804  loss_rpn_cls: 0.6719  loss_rpn_loc: 0.8889  validation_loss: 1.838  time: 0.8348  data_time: 0.0561  lr: 2.4763e-05  max_mem: 10279M
[11/28 12:51:34] d2.data.datasets.coco WARNING: 
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[11/28 12:51:34] d2.data.datasets.coco INFO: Loaded 184 images in COCO format from ./dataset/val/labels_val.json
[11/28 12:51:34] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[11/28 12:51:34] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common.NumpySerializedList'>
[11/28 12:51:34] d2.data.common INFO: Serializing 184 elements to byte tensors and concatenating them all ...
[11/28 12:51:34] d2.data.common INFO: Serialized dataset takes 0.07 MiB
[11/28 12:51:34] d2.evaluation.coco_evaluation WARNING: COCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.
[11/28 12:51:34] d2.evaluation.evaluator INFO: Start inference on 184 batches
[11/28 12:51:35] d2.evaluation.evaluator INFO: Inference done 11/184. Dataloading: 0.0007 s/iter. Inference: 0.0333 s/iter. Eval: 0.0005 s/iter. Total: 0.0344 s/iter. ETA=0:00:05
[11/28 12:51:40] d2.evaluation.evaluator INFO: Inference done 160/184. Dataloading: 0.0009 s/iter. Inference: 0.0322 s/iter. Eval: 0.0005 s/iter. Total: 0.0337 s/iter. ETA=0:00:00
[11/28 12:51:41] d2.evaluation.evaluator INFO: Total inference time: 0:00:06.036250 (0.033722 s / iter per device, on 1 devices)
[11/28 12:51:41] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:00:05 (0.032124 s / iter per device, on 1 devices)
[11/28 12:51:41] d2.evaluation.coco_evaluation INFO: Preparing results for COCO format ...
[11/28 12:51:41] d2.evaluation.coco_evaluation INFO: Saving results to ./output/trial-2022-11-28-12-48-57/inference/coco_instances_results.json
[11/28 12:51:41] d2.evaluation.coco_evaluation INFO: Evaluating predictions with unofficial COCO API...
[11/28 12:51:41] d2.evaluation.fast_eval_api INFO: Evaluate annotation type *bbox*
[11/28 12:51:41] d2.evaluation.fast_eval_api INFO: COCOeval_opt.evaluate() finished in 0.19 seconds.
[11/28 12:51:41] d2.evaluation.fast_eval_api INFO: Accumulating evaluation results...
[11/28 12:51:41] d2.evaluation.fast_eval_api INFO: COCOeval_opt.accumulate() finished in 0.02 seconds.
[11/28 12:51:41] d2.evaluation.coco_evaluation INFO: Evaluation results for bbox: 
|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |
|:-----:|:------:|:------:|:-----:|:-----:|:-----:|
| 0.001 | 0.008  | 0.000  | 0.000 | 0.001 | 0.001 |
[11/28 12:51:41] d2.evaluation.coco_evaluation INFO: Per-category bbox AP: 
| category   | AP    | category   | AP    | category   | AP    |
|:-----------|:------|:-----------|:------|:-----------|:------|
| break      | 0.000 | disc       | 0.002 | shadow     | 0.001 |
[11/28 12:51:41] d2.engine.defaults INFO: Evaluation results for val in csv format:
[11/28 12:51:41] d2.evaluation.testing INFO: copypaste: Task: bbox
[11/28 12:51:41] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[11/28 12:51:41] d2.evaluation.testing INFO: copypaste: 0.0011,0.0083,0.0000,0.0000,0.0007,0.0014
[11/28 12:51:53] d2.utils.events INFO:  eta: 0:03:05  iter: 99  total_loss: 1.517  loss_cls: 0.08006  loss_box_reg: 0.00719  loss_rpn_cls: 0.6421  loss_rpn_loc: 0.7788  validation_loss: 1.817  time: 0.8413  data_time: 0.0557  lr: 3.1007e-05  max_mem: 10405M
[11/28 12:52:04] d2.data.datasets.coco WARNING: 
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[11/28 12:52:04] d2.data.datasets.coco INFO: Loaded 184 images in COCO format from ./dataset/val/labels_val.json
[11/28 12:52:04] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[11/28 12:52:04] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common.NumpySerializedList'>
[11/28 12:52:04] d2.data.common INFO: Serializing 184 elements to byte tensors and concatenating them all ...
[11/28 12:52:04] d2.data.common INFO: Serialized dataset takes 0.07 MiB
[11/28 12:52:04] d2.evaluation.coco_evaluation WARNING: COCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.
[11/28 12:52:04] d2.evaluation.evaluator INFO: Start inference on 184 batches
[11/28 12:52:04] d2.evaluation.evaluator INFO: Inference done 11/184. Dataloading: 0.0006 s/iter. Inference: 0.0321 s/iter. Eval: 0.0005 s/iter. Total: 0.0332 s/iter. ETA=0:00:05
[11/28 12:52:09] d2.evaluation.evaluator INFO: Inference done 158/184. Dataloading: 0.0009 s/iter. Inference: 0.0326 s/iter. Eval: 0.0005 s/iter. Total: 0.0341 s/iter. ETA=0:00:00
[11/28 12:52:10] d2.evaluation.evaluator INFO: Total inference time: 0:00:06.101692 (0.034088 s / iter per device, on 1 devices)
[11/28 12:52:10] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:00:05 (0.032468 s / iter per device, on 1 devices)
[11/28 12:52:10] d2.evaluation.coco_evaluation INFO: Preparing results for COCO format ...
[11/28 12:52:10] d2.evaluation.coco_evaluation INFO: Saving results to ./output/trial-2022-11-28-12-48-57/inference/coco_instances_results.json
[11/28 12:52:10] d2.evaluation.coco_evaluation INFO: Evaluating predictions with unofficial COCO API...
[11/28 12:52:10] d2.evaluation.fast_eval_api INFO: Evaluate annotation type *bbox*
[11/28 12:52:10] d2.evaluation.fast_eval_api INFO: COCOeval_opt.evaluate() finished in 0.07 seconds.
[11/28 12:52:10] d2.evaluation.fast_eval_api INFO: Accumulating evaluation results...
[11/28 12:52:10] d2.evaluation.fast_eval_api INFO: COCOeval_opt.accumulate() finished in 0.02 seconds.
[11/28 12:52:10] d2.evaluation.coco_evaluation INFO: Evaluation results for bbox: 
|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |
|:-----:|:------:|:------:|:-----:|:-----:|:-----:|
| 0.002 | 0.012  | 0.000  | 0.000 | 0.000 | 0.004 |
[11/28 12:52:10] d2.evaluation.coco_evaluation INFO: Per-category bbox AP: 
| category   | AP    | category   | AP    | category   | AP    |
|:-----------|:------|:-----------|:------|:-----------|:------|
| break      | 0.000 | disc       | 0.001 | shadow     | 0.003 |
[11/28 12:52:10] d2.engine.defaults INFO: Evaluation results for val in csv format:
[11/28 12:52:10] d2.evaluation.testing INFO: copypaste: Task: bbox
[11/28 12:52:10] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[11/28 12:52:11] d2.evaluation.testing INFO: copypaste: 0.0016,0.0115,0.0000,0.0000,0.0001,0.0037
[11/28 12:52:26] d2.utils.events INFO:  eta: 0:02:49  iter: 119  total_loss: 1.331  loss_cls: 0.09578  loss_box_reg: 0.006374  loss_rpn_cls: 0.6086  loss_rpn_loc: 0.6189  validation_loss: 1.796  time: 0.8502  data_time: 0.0538  lr: 3.725e-05  max_mem: 10405M
[11/28 12:52:34] d2.data.datasets.coco WARNING: 
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[11/28 12:52:34] d2.data.datasets.coco INFO: Loaded 184 images in COCO format from ./dataset/val/labels_val.json
[11/28 12:52:34] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[11/28 12:52:34] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common.NumpySerializedList'>
[11/28 12:52:34] d2.data.common INFO: Serializing 184 elements to byte tensors and concatenating them all ...
[11/28 12:52:34] d2.data.common INFO: Serialized dataset takes 0.07 MiB
[11/28 12:52:34] d2.evaluation.coco_evaluation WARNING: COCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.
[11/28 12:52:34] d2.evaluation.evaluator INFO: Start inference on 184 batches
[11/28 12:52:34] d2.evaluation.evaluator INFO: Inference done 11/184. Dataloading: 0.0007 s/iter. Inference: 0.0334 s/iter. Eval: 0.0005 s/iter. Total: 0.0346 s/iter. ETA=0:00:05
[11/28 12:52:39] d2.evaluation.evaluator INFO: Inference done 156/184. Dataloading: 0.0009 s/iter. Inference: 0.0331 s/iter. Eval: 0.0005 s/iter. Total: 0.0346 s/iter. ETA=0:00:00
[11/28 12:52:40] d2.evaluation.evaluator INFO: Total inference time: 0:00:06.174308 (0.034493 s / iter per device, on 1 devices)
[11/28 12:52:40] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:00:05 (0.032894 s / iter per device, on 1 devices)
[11/28 12:52:40] d2.evaluation.coco_evaluation INFO: Preparing results for COCO format ...
[11/28 12:52:40] d2.evaluation.coco_evaluation INFO: Saving results to ./output/trial-2022-11-28-12-48-57/inference/coco_instances_results.json
[11/28 12:52:40] d2.evaluation.coco_evaluation INFO: Evaluating predictions with unofficial COCO API...
[11/28 12:52:40] d2.evaluation.fast_eval_api INFO: Evaluate annotation type *bbox*
[11/28 12:52:40] d2.evaluation.fast_eval_api INFO: COCOeval_opt.evaluate() finished in 0.07 seconds.
[11/28 12:52:40] d2.evaluation.fast_eval_api INFO: Accumulating evaluation results...
[11/28 12:52:40] d2.evaluation.fast_eval_api INFO: COCOeval_opt.accumulate() finished in 0.02 seconds.
[11/28 12:52:40] d2.evaluation.coco_evaluation INFO: Evaluation results for bbox: 
|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |
|:-----:|:------:|:------:|:-----:|:-----:|:-----:|
| 0.001 | 0.009  | 0.000  | 0.000 | 0.000 | 0.004 |
[11/28 12:52:40] d2.evaluation.coco_evaluation INFO: Per-category bbox AP: 
| category   | AP    | category   | AP    | category   | AP    |
|:-----------|:------|:-----------|:------|:-----------|:------|
| break      | 0.000 | disc       | 0.001 | shadow     | 0.003 |
[11/28 12:52:41] d2.engine.defaults INFO: Evaluation results for val in csv format:
[11/28 12:52:41] d2.evaluation.testing INFO: copypaste: Task: bbox
[11/28 12:52:41] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[11/28 12:52:41] d2.evaluation.testing INFO: copypaste: 0.0014,0.0093,0.0000,0.0000,0.0000,0.0039
[11/28 12:53:00] d2.utils.events INFO:  eta: 0:02:34  iter: 139  total_loss: 1.29  loss_cls: 0.08011  loss_box_reg: 0.0096  loss_rpn_cls: 0.5484  loss_rpn_loc: 0.6437  validation_loss: 1.767  time: 0.8635  data_time: 0.0584  lr: 4.3494e-05  max_mem: 10405M
[11/28 12:53:04] d2.data.datasets.coco WARNING: 
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[11/28 12:53:04] d2.data.datasets.coco INFO: Loaded 184 images in COCO format from ./dataset/val/labels_val.json
[11/28 12:53:04] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[11/28 12:53:04] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common.NumpySerializedList'>
[11/28 12:53:04] d2.data.common INFO: Serializing 184 elements to byte tensors and concatenating them all ...
[11/28 12:53:04] d2.data.common INFO: Serialized dataset takes 0.07 MiB
[11/28 12:53:04] d2.evaluation.coco_evaluation WARNING: COCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.
[11/28 12:53:04] d2.evaluation.evaluator INFO: Start inference on 184 batches
[11/28 12:53:05] d2.evaluation.evaluator INFO: Inference done 11/184. Dataloading: 0.0007 s/iter. Inference: 0.0338 s/iter. Eval: 0.0004 s/iter. Total: 0.0348 s/iter. ETA=0:00:06
[11/28 12:53:10] d2.evaluation.evaluator INFO: Inference done 155/184. Dataloading: 0.0009 s/iter. Inference: 0.0334 s/iter. Eval: 0.0004 s/iter. Total: 0.0348 s/iter. ETA=0:00:01
[11/28 12:53:11] d2.evaluation.evaluator INFO: Total inference time: 0:00:06.213932 (0.034715 s / iter per device, on 1 devices)
[11/28 12:53:11] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:00:05 (0.033208 s / iter per device, on 1 devices)
[11/28 12:53:11] d2.evaluation.coco_evaluation INFO: Preparing results for COCO format ...
[11/28 12:53:11] d2.evaluation.coco_evaluation INFO: Saving results to ./output/trial-2022-11-28-12-48-57/inference/coco_instances_results.json
[11/28 12:53:11] d2.evaluation.coco_evaluation INFO: Evaluating predictions with unofficial COCO API...
[11/28 12:53:11] d2.evaluation.fast_eval_api INFO: Evaluate annotation type *bbox*
[11/28 12:53:11] d2.evaluation.fast_eval_api INFO: COCOeval_opt.evaluate() finished in 0.03 seconds.
[11/28 12:53:11] d2.evaluation.fast_eval_api INFO: Accumulating evaluation results...
[11/28 12:53:11] d2.evaluation.fast_eval_api INFO: COCOeval_opt.accumulate() finished in 0.01 seconds.
[11/28 12:53:11] d2.evaluation.coco_evaluation INFO: Evaluation results for bbox: 
|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |
|:-----:|:------:|:------:|:-----:|:-----:|:-----:|
| 0.001 | 0.009  | 0.000  | 0.000 | 0.000 | 0.003 |
[11/28 12:53:11] d2.evaluation.coco_evaluation INFO: Per-category bbox AP: 
| category   | AP    | category   | AP    | category   | AP    |
|:-----------|:------|:-----------|:------|:-----------|:------|
| break      | 0.000 | disc       | 0.000 | shadow     | 0.004 |
[11/28 12:53:11] d2.engine.defaults INFO: Evaluation results for val in csv format:
[11/28 12:53:11] d2.evaluation.testing INFO: copypaste: Task: bbox
[11/28 12:53:11] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[11/28 12:53:11] d2.evaluation.testing INFO: copypaste: 0.0014,0.0085,0.0000,0.0000,0.0000,0.0031
[11/28 12:53:38] d2.data.datasets.coco WARNING: 
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[11/28 12:53:38] d2.data.datasets.coco INFO: Loaded 184 images in COCO format from ./dataset/val/labels_val.json
[11/28 12:53:38] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[11/28 12:53:38] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common.NumpySerializedList'>
[11/28 12:53:38] d2.data.common INFO: Serializing 184 elements to byte tensors and concatenating them all ...
[11/28 12:53:38] d2.data.common INFO: Serialized dataset takes 0.07 MiB
[11/28 12:53:38] d2.evaluation.coco_evaluation WARNING: COCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.
[11/28 12:53:38] d2.evaluation.evaluator INFO: Start inference on 184 batches
[11/28 12:53:39] d2.evaluation.evaluator INFO: Inference done 11/184. Dataloading: 0.0008 s/iter. Inference: 0.0336 s/iter. Eval: 0.0004 s/iter. Total: 0.0348 s/iter. ETA=0:00:06
[11/28 12:53:44] d2.evaluation.evaluator INFO: Inference done 155/184. Dataloading: 0.0009 s/iter. Inference: 0.0334 s/iter. Eval: 0.0003 s/iter. Total: 0.0348 s/iter. ETA=0:00:01
[11/28 12:53:45] d2.evaluation.evaluator INFO: Total inference time: 0:00:06.209405 (0.034689 s / iter per device, on 1 devices)
[11/28 12:53:45] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:00:05 (0.033197 s / iter per device, on 1 devices)
[11/28 12:53:45] d2.evaluation.coco_evaluation INFO: Preparing results for COCO format ...
[11/28 12:53:45] d2.evaluation.coco_evaluation INFO: Saving results to ./output/trial-2022-11-28-12-48-57/inference/coco_instances_results.json
[11/28 12:53:45] d2.evaluation.coco_evaluation INFO: Evaluating predictions with unofficial COCO API...
[11/28 12:53:45] d2.evaluation.fast_eval_api INFO: Evaluate annotation type *bbox*
[11/28 12:53:45] d2.evaluation.fast_eval_api INFO: COCOeval_opt.evaluate() finished in 0.02 seconds.
[11/28 12:53:45] d2.evaluation.fast_eval_api INFO: Accumulating evaluation results...
[11/28 12:53:45] d2.evaluation.fast_eval_api INFO: COCOeval_opt.accumulate() finished in 0.01 seconds.
[11/28 12:53:45] d2.evaluation.coco_evaluation INFO: Evaluation results for bbox: 
|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |
|:-----:|:------:|:------:|:-----:|:-----:|:-----:|
| 0.001 | 0.002  | 0.002  | 0.000 | 0.000 | 0.002 |
[11/28 12:53:45] d2.evaluation.coco_evaluation INFO: Per-category bbox AP: 
| category   | AP    | category   | AP    | category   | AP    |
|:-----------|:------|:-----------|:------|:-----------|:------|
| break      | 0.000 | disc       | 0.000 | shadow     | 0.004 |
[11/28 12:53:45] d2.engine.defaults INFO: Evaluation results for val in csv format:
[11/28 12:53:45] d2.evaluation.testing INFO: copypaste: Task: bbox
[11/28 12:53:45] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[11/28 12:53:45] d2.evaluation.testing INFO: copypaste: 0.0012,0.0020,0.0020,0.0000,0.0000,0.0024
[11/28 12:53:53] d2.utils.events INFO:  eta: 0:02:18  iter: 159  total_loss: 1.051  loss_cls: 0.1191  loss_box_reg: 0.03731  loss_rpn_cls: 0.4535  loss_rpn_loc: 0.431  validation_loss: 1.719  time: 0.8942  data_time: 0.0532  lr: 4.9738e-05  max_mem: 10405M
[11/28 12:54:12] d2.data.datasets.coco WARNING: 
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[11/28 12:54:12] d2.data.datasets.coco INFO: Loaded 184 images in COCO format from ./dataset/val/labels_val.json
[11/28 12:54:12] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[11/28 12:54:12] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common.NumpySerializedList'>
[11/28 12:54:12] d2.data.common INFO: Serializing 184 elements to byte tensors and concatenating them all ...
[11/28 12:54:12] d2.data.common INFO: Serialized dataset takes 0.07 MiB
[11/28 12:54:12] d2.evaluation.coco_evaluation WARNING: COCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.
[11/28 12:54:12] d2.evaluation.evaluator INFO: Start inference on 184 batches
[11/28 12:54:13] d2.evaluation.evaluator INFO: Inference done 11/184. Dataloading: 0.0007 s/iter. Inference: 0.0338 s/iter. Eval: 0.0003 s/iter. Total: 0.0347 s/iter. ETA=0:00:06
[11/28 12:54:18] d2.evaluation.evaluator INFO: Inference done 154/184. Dataloading: 0.0009 s/iter. Inference: 0.0339 s/iter. Eval: 0.0003 s/iter. Total: 0.0352 s/iter. ETA=0:00:01
[11/28 12:54:19] d2.evaluation.evaluator INFO: Total inference time: 0:00:06.265345 (0.035002 s / iter per device, on 1 devices)
[11/28 12:54:19] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:00:06 (0.033533 s / iter per device, on 1 devices)
[11/28 12:54:19] d2.evaluation.coco_evaluation INFO: Preparing results for COCO format ...
[11/28 12:54:19] d2.evaluation.coco_evaluation INFO: Saving results to ./output/trial-2022-11-28-12-48-57/inference/coco_instances_results.json
[11/28 12:54:19] d2.evaluation.coco_evaluation INFO: Evaluating predictions with unofficial COCO API...
[11/28 12:54:19] d2.evaluation.fast_eval_api INFO: Evaluate annotation type *bbox*
[11/28 12:54:19] d2.evaluation.fast_eval_api INFO: COCOeval_opt.evaluate() finished in 0.02 seconds.
[11/28 12:54:19] d2.evaluation.fast_eval_api INFO: Accumulating evaluation results...
[11/28 12:54:19] d2.evaluation.fast_eval_api INFO: COCOeval_opt.accumulate() finished in 0.01 seconds.
[11/28 12:54:19] d2.evaluation.coco_evaluation INFO: Evaluation results for bbox: 
|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |
|:-----:|:------:|:------:|:-----:|:-----:|:-----:|
| 0.000 | 0.000  | 0.000  | 0.000 | 0.000 | 0.000 |
[11/28 12:54:19] d2.evaluation.coco_evaluation INFO: Per-category bbox AP: 
| category   | AP    | category   | AP    | category   | AP    |
|:-----------|:------|:-----------|:------|:-----------|:------|
| break      | 0.000 | disc       | 0.000 | shadow     | 0.000 |
[11/28 12:54:19] d2.engine.defaults INFO: Evaluation results for val in csv format:
[11/28 12:54:19] d2.evaluation.testing INFO: copypaste: Task: bbox
[11/28 12:54:19] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[11/28 12:54:19] d2.evaluation.testing INFO: copypaste: 0.0000,0.0000,0.0000,0.0000,0.0000,0.0000
[11/28 12:54:32] d2.utils.events INFO:  eta: 0:02:03  iter: 179  total_loss: 1.001  loss_cls: 0.1084  loss_box_reg: 0.03552  loss_rpn_cls: 0.3887  loss_rpn_loc: 0.4796  validation_loss: 1.701  time: 0.9252  data_time: 0.0578  lr: 5.5982e-05  max_mem: 10405M
[11/28 12:54:46] d2.data.datasets.coco WARNING: 
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[11/28 12:54:46] d2.data.datasets.coco INFO: Loaded 184 images in COCO format from ./dataset/val/labels_val.json
[11/28 12:54:46] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[11/28 12:54:46] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common.NumpySerializedList'>
[11/28 12:54:46] d2.data.common INFO: Serializing 184 elements to byte tensors and concatenating them all ...
[11/28 12:54:46] d2.data.common INFO: Serialized dataset takes 0.07 MiB
[11/28 12:54:46] d2.evaluation.coco_evaluation WARNING: COCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.
[11/28 12:54:46] d2.evaluation.evaluator INFO: Start inference on 184 batches
[11/28 12:54:47] d2.evaluation.evaluator INFO: Inference done 11/184. Dataloading: 0.0007 s/iter. Inference: 0.0324 s/iter. Eval: 0.0002 s/iter. Total: 0.0334 s/iter. ETA=0:00:05
[11/28 12:54:52] d2.evaluation.evaluator INFO: Inference done 162/184. Dataloading: 0.0009 s/iter. Inference: 0.0319 s/iter. Eval: 0.0002 s/iter. Total: 0.0331 s/iter. ETA=0:00:00
[11/28 12:54:53] d2.evaluation.evaluator INFO: Total inference time: 0:00:05.942297 (0.033197 s / iter per device, on 1 devices)
[11/28 12:54:53] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:00:05 (0.031816 s / iter per device, on 1 devices)
[11/28 12:54:53] d2.evaluation.coco_evaluation INFO: Preparing results for COCO format ...
[11/28 12:54:53] d2.evaluation.coco_evaluation INFO: Saving results to ./output/trial-2022-11-28-12-48-57/inference/coco_instances_results.json
[11/28 12:54:53] d2.evaluation.coco_evaluation INFO: Evaluating predictions with unofficial COCO API...
[11/28 12:54:53] d2.evaluation.fast_eval_api INFO: Evaluate annotation type *bbox*
[11/28 12:54:53] d2.evaluation.fast_eval_api INFO: COCOeval_opt.evaluate() finished in 0.02 seconds.
[11/28 12:54:53] d2.evaluation.fast_eval_api INFO: Accumulating evaluation results...
[11/28 12:54:53] d2.evaluation.fast_eval_api INFO: COCOeval_opt.accumulate() finished in 0.01 seconds.
[11/28 12:54:53] d2.evaluation.coco_evaluation INFO: Evaluation results for bbox: 
|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |
|:-----:|:------:|:------:|:-----:|:-----:|:-----:|
| 0.000 | 0.000  | 0.000  | 0.000 | 0.000 | 0.000 |
[11/28 12:54:53] d2.evaluation.coco_evaluation INFO: Per-category bbox AP: 
| category   | AP    | category   | AP    | category   | AP    |
|:-----------|:------|:-----------|:------|:-----------|:------|
| break      | 0.000 | disc       | 0.000 | shadow     | 0.000 |
[11/28 12:54:53] d2.engine.defaults INFO: Evaluation results for val in csv format:
[11/28 12:54:53] d2.evaluation.testing INFO: copypaste: Task: bbox
[11/28 12:54:53] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[11/28 12:54:53] d2.evaluation.testing INFO: copypaste: 0.0000,0.0000,0.0000,0.0000,0.0000,0.0000
[11/28 12:55:11] d2.utils.events INFO:  eta: 0:01:46  iter: 199  total_loss: 0.8263  loss_cls: 0.1028  loss_box_reg: 0.03736  loss_rpn_cls: 0.2975  loss_rpn_loc: 0.3816  validation_loss: 1.65  time: 0.9496  data_time: 0.0547  lr: 6.2225e-05  max_mem: 10405M
[11/28 12:55:20] d2.data.datasets.coco WARNING: 
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[11/28 12:55:20] d2.data.datasets.coco INFO: Loaded 184 images in COCO format from ./dataset/val/labels_val.json
[11/28 12:55:20] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[11/28 12:55:20] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common.NumpySerializedList'>
[11/28 12:55:20] d2.data.common INFO: Serializing 184 elements to byte tensors and concatenating them all ...
[11/28 12:55:20] d2.data.common INFO: Serialized dataset takes 0.07 MiB
[11/28 12:55:20] d2.evaluation.coco_evaluation WARNING: COCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.
[11/28 12:55:20] d2.evaluation.evaluator INFO: Start inference on 184 batches
[11/28 12:55:21] d2.evaluation.evaluator INFO: Inference done 11/184. Dataloading: 0.0007 s/iter. Inference: 0.0331 s/iter. Eval: 0.0001 s/iter. Total: 0.0339 s/iter. ETA=0:00:05
[11/28 12:55:26] d2.evaluation.evaluator INFO: Inference done 159/184. Dataloading: 0.0009 s/iter. Inference: 0.0327 s/iter. Eval: 0.0001 s/iter. Total: 0.0338 s/iter. ETA=0:00:00
[11/28 12:55:27] d2.evaluation.evaluator INFO: Total inference time: 0:00:06.087051 (0.034006 s / iter per device, on 1 devices)
[11/28 12:55:27] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:00:05 (0.032729 s / iter per device, on 1 devices)
[11/28 12:55:27] d2.evaluation.coco_evaluation INFO: Preparing results for COCO format ...
[11/28 12:55:27] d2.evaluation.coco_evaluation INFO: Saving results to ./output/trial-2022-11-28-12-48-57/inference/coco_instances_results.json
[11/28 12:55:27] d2.evaluation.coco_evaluation INFO: Evaluating predictions with unofficial COCO API...
[11/28 12:55:27] d2.evaluation.fast_eval_api INFO: Evaluate annotation type *bbox*
[11/28 12:55:27] d2.evaluation.fast_eval_api INFO: COCOeval_opt.evaluate() finished in 0.02 seconds.
[11/28 12:55:27] d2.evaluation.fast_eval_api INFO: Accumulating evaluation results...
[11/28 12:55:27] d2.evaluation.fast_eval_api INFO: COCOeval_opt.accumulate() finished in 0.01 seconds.
[11/28 12:55:27] d2.evaluation.coco_evaluation INFO: Evaluation results for bbox: 
|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |
|:-----:|:------:|:------:|:-----:|:-----:|:-----:|
| 0.000 | 0.000  | 0.000  | 0.000 | 0.000 | 0.000 |
[11/28 12:55:27] d2.evaluation.coco_evaluation INFO: Per-category bbox AP: 
| category   | AP    | category   | AP    | category   | AP    |
|:-----------|:------|:-----------|:------|:-----------|:------|
| break      | 0.000 | disc       | 0.000 | shadow     | 0.000 |
[11/28 12:55:27] d2.engine.defaults INFO: Evaluation results for val in csv format:
[11/28 12:55:27] d2.evaluation.testing INFO: copypaste: Task: bbox
[11/28 12:55:27] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[11/28 12:55:27] d2.evaluation.testing INFO: copypaste: 0.0000,0.0000,0.0000,0.0000,0.0000,0.0000
[11/28 12:55:50] d2.utils.events INFO:  eta: 0:01:30  iter: 219  total_loss: 0.6973  loss_cls: 0.101  loss_box_reg: 0.04534  loss_rpn_cls: 0.2349  loss_rpn_loc: 0.3126  validation_loss: 1.599  time: 0.9669  data_time: 0.0554  lr: 6.8469e-05  max_mem: 10405M
[11/28 12:55:54] d2.data.datasets.coco WARNING: 
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[11/28 12:55:54] d2.data.datasets.coco INFO: Loaded 184 images in COCO format from ./dataset/val/labels_val.json
[11/28 12:55:54] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[11/28 12:55:54] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common.NumpySerializedList'>
[11/28 12:55:54] d2.data.common INFO: Serializing 184 elements to byte tensors and concatenating them all ...
[11/28 12:55:54] d2.data.common INFO: Serialized dataset takes 0.07 MiB
[11/28 12:55:54] d2.evaluation.coco_evaluation WARNING: COCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.
[11/28 12:55:54] d2.evaluation.evaluator INFO: Start inference on 184 batches
[11/28 12:55:55] d2.evaluation.evaluator INFO: Inference done 11/184. Dataloading: 0.0007 s/iter. Inference: 0.0338 s/iter. Eval: 0.0004 s/iter. Total: 0.0348 s/iter. ETA=0:00:06
[11/28 12:56:00] d2.evaluation.evaluator INFO: Inference done 156/184. Dataloading: 0.0009 s/iter. Inference: 0.0333 s/iter. Eval: 0.0004 s/iter. Total: 0.0346 s/iter. ETA=0:00:00
[11/28 12:56:01] d2.evaluation.evaluator INFO: Total inference time: 0:00:06.203078 (0.034654 s / iter per device, on 1 devices)
[11/28 12:56:01] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:00:05 (0.033129 s / iter per device, on 1 devices)
[11/28 12:56:01] d2.evaluation.coco_evaluation INFO: Preparing results for COCO format ...
[11/28 12:56:01] d2.evaluation.coco_evaluation INFO: Saving results to ./output/trial-2022-11-28-12-48-57/inference/coco_instances_results.json
[11/28 12:56:01] d2.evaluation.coco_evaluation INFO: Evaluating predictions with unofficial COCO API...
[11/28 12:56:01] d2.evaluation.fast_eval_api INFO: Evaluate annotation type *bbox*
[11/28 12:56:01] d2.evaluation.fast_eval_api INFO: COCOeval_opt.evaluate() finished in 0.02 seconds.
[11/28 12:56:01] d2.evaluation.fast_eval_api INFO: Accumulating evaluation results...
[11/28 12:56:01] d2.evaluation.fast_eval_api INFO: COCOeval_opt.accumulate() finished in 0.01 seconds.
[11/28 12:56:01] d2.evaluation.coco_evaluation INFO: Evaluation results for bbox: 
|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |
|:-----:|:------:|:------:|:-----:|:-----:|:-----:|
| 0.000 | 0.001  | 0.000  | 0.000 | 0.000 | 0.000 |
[11/28 12:56:01] d2.evaluation.coco_evaluation INFO: Per-category bbox AP: 
| category   | AP    | category   | AP    | category   | AP    |
|:-----------|:------|:-----------|:------|:-----------|:------|
| break      | 0.000 | disc       | 0.000 | shadow     | 0.000 |
[11/28 12:56:01] d2.engine.defaults INFO: Evaluation results for val in csv format:
[11/28 12:56:01] d2.evaluation.testing INFO: copypaste: Task: bbox
[11/28 12:56:01] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[11/28 12:56:01] d2.evaluation.testing INFO: copypaste: 0.0001,0.0005,0.0000,0.0000,0.0002,0.0000
[11/28 12:56:29] d2.data.datasets.coco WARNING: 
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[11/28 12:56:29] d2.data.datasets.coco INFO: Loaded 184 images in COCO format from ./dataset/val/labels_val.json
[11/28 12:56:29] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[11/28 12:56:29] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common.NumpySerializedList'>
[11/28 12:56:29] d2.data.common INFO: Serializing 184 elements to byte tensors and concatenating them all ...
[11/28 12:56:29] d2.data.common INFO: Serialized dataset takes 0.07 MiB
[11/28 12:56:29] d2.evaluation.coco_evaluation WARNING: COCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.
[11/28 12:56:29] d2.evaluation.evaluator INFO: Start inference on 184 batches
[11/28 12:56:29] d2.evaluation.evaluator INFO: Inference done 11/184. Dataloading: 0.0007 s/iter. Inference: 0.0339 s/iter. Eval: 0.0004 s/iter. Total: 0.0350 s/iter. ETA=0:00:06
[11/28 12:56:34] d2.evaluation.evaluator INFO: Inference done 152/184. Dataloading: 0.0009 s/iter. Inference: 0.0343 s/iter. Eval: 0.0004 s/iter. Total: 0.0356 s/iter. ETA=0:00:01
[11/28 12:56:35] d2.evaluation.evaluator INFO: Total inference time: 0:00:06.388535 (0.035690 s / iter per device, on 1 devices)
[11/28 12:56:35] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:00:06 (0.034164 s / iter per device, on 1 devices)
[11/28 12:56:35] d2.evaluation.coco_evaluation INFO: Preparing results for COCO format ...
[11/28 12:56:35] d2.evaluation.coco_evaluation INFO: Saving results to ./output/trial-2022-11-28-12-48-57/inference/coco_instances_results.json
[11/28 12:56:35] d2.evaluation.coco_evaluation INFO: Evaluating predictions with unofficial COCO API...
[11/28 12:56:35] d2.evaluation.fast_eval_api INFO: Evaluate annotation type *bbox*
[11/28 12:56:35] d2.evaluation.fast_eval_api INFO: COCOeval_opt.evaluate() finished in 0.02 seconds.
[11/28 12:56:35] d2.evaluation.fast_eval_api INFO: Accumulating evaluation results...
[11/28 12:56:35] d2.evaluation.fast_eval_api INFO: COCOeval_opt.accumulate() finished in 0.01 seconds.
[11/28 12:56:35] d2.evaluation.coco_evaluation INFO: Evaluation results for bbox: 
|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |
|:-----:|:------:|:------:|:-----:|:-----:|:-----:|
| 0.000 | 0.000  | 0.000  | 0.000 | 0.000 | 0.000 |
[11/28 12:56:35] d2.evaluation.coco_evaluation INFO: Per-category bbox AP: 
| category   | AP    | category   | AP    | category   | AP    |
|:-----------|:------|:-----------|:------|:-----------|:------|
| break      | 0.000 | disc       | 0.000 | shadow     | 0.000 |
[11/28 12:56:35] d2.engine.defaults INFO: Evaluation results for val in csv format:
[11/28 12:56:35] d2.evaluation.testing INFO: copypaste: Task: bbox
[11/28 12:56:35] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[11/28 12:56:35] d2.evaluation.testing INFO: copypaste: 0.0000,0.0000,0.0000,0.0000,0.0000,0.0000
[11/28 12:56:45] d2.utils.events INFO:  eta: 0:01:13  iter: 239  total_loss: 0.6898  loss_cls: 0.08978  loss_box_reg: 0.0394  loss_rpn_cls: 0.1887  loss_rpn_loc: 0.3467  validation_loss: 1.384  time: 0.9807  data_time: 0.0552  lr: 7.4713e-05  max_mem: 10405M
[11/28 12:57:03] d2.data.datasets.coco WARNING: 
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[11/28 12:57:03] d2.data.datasets.coco INFO: Loaded 184 images in COCO format from ./dataset/val/labels_val.json
[11/28 12:57:03] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[11/28 12:57:03] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common.NumpySerializedList'>
[11/28 12:57:03] d2.data.common INFO: Serializing 184 elements to byte tensors and concatenating them all ...
[11/28 12:57:03] d2.data.common INFO: Serialized dataset takes 0.07 MiB
[11/28 12:57:03] d2.evaluation.coco_evaluation WARNING: COCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.
[11/28 12:57:03] d2.evaluation.evaluator INFO: Start inference on 184 batches
[11/28 12:57:04] d2.evaluation.evaluator INFO: Inference done 11/184. Dataloading: 0.0008 s/iter. Inference: 0.0338 s/iter. Eval: 0.0004 s/iter. Total: 0.0349 s/iter. ETA=0:00:06
[11/28 12:57:09] d2.evaluation.evaluator INFO: Inference done 146/184. Dataloading: 0.0009 s/iter. Inference: 0.0356 s/iter. Eval: 0.0004 s/iter. Total: 0.0370 s/iter. ETA=0:00:01
[11/28 12:57:10] d2.evaluation.evaluator INFO: Total inference time: 0:00:06.543694 (0.036557 s / iter per device, on 1 devices)
[11/28 12:57:10] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:00:06 (0.034994 s / iter per device, on 1 devices)
[11/28 12:57:10] d2.evaluation.coco_evaluation INFO: Preparing results for COCO format ...
[11/28 12:57:10] d2.evaluation.coco_evaluation INFO: Saving results to ./output/trial-2022-11-28-12-48-57/inference/coco_instances_results.json
[11/28 12:57:10] d2.evaluation.coco_evaluation INFO: Evaluating predictions with unofficial COCO API...
[11/28 12:57:10] d2.evaluation.fast_eval_api INFO: Evaluate annotation type *bbox*
[11/28 12:57:10] d2.evaluation.fast_eval_api INFO: COCOeval_opt.evaluate() finished in 0.02 seconds.
[11/28 12:57:10] d2.evaluation.fast_eval_api INFO: Accumulating evaluation results...
[11/28 12:57:10] d2.evaluation.fast_eval_api INFO: COCOeval_opt.accumulate() finished in 0.01 seconds.
[11/28 12:57:10] d2.evaluation.coco_evaluation INFO: Evaluation results for bbox: 
|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |
|:-----:|:------:|:------:|:-----:|:-----:|:-----:|
| 0.000 | 0.000  | 0.000  | 0.000 | 0.000 | 0.000 |
[11/28 12:57:10] d2.evaluation.coco_evaluation INFO: Per-category bbox AP: 
| category   | AP    | category   | AP    | category   | AP    |
|:-----------|:------|:-----------|:------|:-----------|:------|
| break      | 0.000 | disc       | 0.000 | shadow     | 0.000 |
[11/28 12:57:10] d2.engine.defaults INFO: Evaluation results for val in csv format:
[11/28 12:57:10] d2.evaluation.testing INFO: copypaste: Task: bbox
[11/28 12:57:10] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[11/28 12:57:10] d2.evaluation.testing INFO: copypaste: 0.0000,0.0000,0.0000,0.0000,0.0000,0.0000
[11/28 12:57:24] d2.utils.events INFO:  eta: 0:00:56  iter: 259  total_loss: 0.5944  loss_cls: 0.09212  loss_box_reg: 0.04241  loss_rpn_cls: 0.1896  loss_rpn_loc: 0.256  validation_loss: 1.296  time: 0.9931  data_time: 0.0543  lr: 8.0957e-05  max_mem: 10405M
[11/28 12:57:37] d2.data.datasets.coco WARNING: 
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[11/28 12:57:37] d2.data.datasets.coco INFO: Loaded 184 images in COCO format from ./dataset/val/labels_val.json
[11/28 12:57:37] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[11/28 12:57:37] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common.NumpySerializedList'>
[11/28 12:57:37] d2.data.common INFO: Serializing 184 elements to byte tensors and concatenating them all ...
[11/28 12:57:38] d2.data.common INFO: Serialized dataset takes 0.07 MiB
[11/28 12:57:38] d2.evaluation.coco_evaluation WARNING: COCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.
[11/28 12:57:38] d2.evaluation.evaluator INFO: Start inference on 184 batches
[11/28 12:57:38] d2.evaluation.evaluator INFO: Inference done 11/184. Dataloading: 0.0008 s/iter. Inference: 0.0340 s/iter. Eval: 0.0003 s/iter. Total: 0.0351 s/iter. ETA=0:00:06
[11/28 12:57:43] d2.evaluation.evaluator INFO: Inference done 151/184. Dataloading: 0.0009 s/iter. Inference: 0.0344 s/iter. Eval: 0.0003 s/iter. Total: 0.0357 s/iter. ETA=0:00:01
[11/28 12:57:44] d2.evaluation.evaluator INFO: Total inference time: 0:00:06.367769 (0.035574 s / iter per device, on 1 devices)
[11/28 12:57:44] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:00:06 (0.034105 s / iter per device, on 1 devices)
[11/28 12:57:44] d2.evaluation.coco_evaluation INFO: Preparing results for COCO format ...
[11/28 12:57:44] d2.evaluation.coco_evaluation INFO: Saving results to ./output/trial-2022-11-28-12-48-57/inference/coco_instances_results.json
[11/28 12:57:44] d2.evaluation.coco_evaluation INFO: Evaluating predictions with unofficial COCO API...
[11/28 12:57:44] d2.evaluation.fast_eval_api INFO: Evaluate annotation type *bbox*
[11/28 12:57:44] d2.evaluation.fast_eval_api INFO: COCOeval_opt.evaluate() finished in 0.02 seconds.
[11/28 12:57:44] d2.evaluation.fast_eval_api INFO: Accumulating evaluation results...
[11/28 12:57:44] d2.evaluation.fast_eval_api INFO: COCOeval_opt.accumulate() finished in 0.01 seconds.
[11/28 12:57:44] d2.evaluation.coco_evaluation INFO: Evaluation results for bbox: 
|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |
|:-----:|:------:|:------:|:-----:|:-----:|:-----:|
| 0.001 | 0.002  | 0.001  | 0.000 | 0.004 | 0.000 |
[11/28 12:57:44] d2.evaluation.coco_evaluation INFO: Per-category bbox AP: 
| category   | AP    | category   | AP    | category   | AP    |
|:-----------|:------|:-----------|:------|:-----------|:------|
| break      | 0.003 | disc       | 0.000 | shadow     | 0.000 |
[11/28 12:57:44] d2.engine.defaults INFO: Evaluation results for val in csv format:
[11/28 12:57:44] d2.evaluation.testing INFO: copypaste: Task: bbox
[11/28 12:57:44] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[11/28 12:57:44] d2.evaluation.testing INFO: copypaste: 0.0010,0.0022,0.0014,0.0000,0.0037,0.0000
[11/28 12:58:02] d2.utils.events INFO:  eta: 0:00:40  iter: 279  total_loss: 0.6638  loss_cls: 0.09312  loss_box_reg: 0.04521  loss_rpn_cls: 0.1872  loss_rpn_loc: 0.3345  validation_loss: 1.209  time: 1.0026  data_time: 0.0540  lr: 8.72e-05  max_mem: 10405M
[11/28 12:58:11] d2.data.datasets.coco WARNING: 
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[11/28 12:58:11] d2.data.datasets.coco INFO: Loaded 184 images in COCO format from ./dataset/val/labels_val.json
[11/28 12:58:11] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[11/28 12:58:11] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common.NumpySerializedList'>
[11/28 12:58:11] d2.data.common INFO: Serializing 184 elements to byte tensors and concatenating them all ...
[11/28 12:58:11] d2.data.common INFO: Serialized dataset takes 0.07 MiB
[11/28 12:58:11] d2.evaluation.coco_evaluation WARNING: COCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.
[11/28 12:58:11] d2.evaluation.evaluator INFO: Start inference on 184 batches
[11/28 12:58:12] d2.evaluation.evaluator INFO: Inference done 11/184. Dataloading: 0.0007 s/iter. Inference: 0.0343 s/iter. Eval: 0.0003 s/iter. Total: 0.0353 s/iter. ETA=0:00:06
[11/28 12:58:17] d2.evaluation.evaluator INFO: Inference done 155/184. Dataloading: 0.0009 s/iter. Inference: 0.0335 s/iter. Eval: 0.0003 s/iter. Total: 0.0348 s/iter. ETA=0:00:01
[11/28 12:58:18] d2.evaluation.evaluator INFO: Total inference time: 0:00:06.220683 (0.034752 s / iter per device, on 1 devices)
[11/28 12:58:18] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:00:05 (0.033265 s / iter per device, on 1 devices)
[11/28 12:58:18] d2.evaluation.coco_evaluation INFO: Preparing results for COCO format ...
[11/28 12:58:18] d2.evaluation.coco_evaluation INFO: Saving results to ./output/trial-2022-11-28-12-48-57/inference/coco_instances_results.json
[11/28 12:58:18] d2.evaluation.coco_evaluation INFO: Evaluating predictions with unofficial COCO API...
[11/28 12:58:18] d2.evaluation.fast_eval_api INFO: Evaluate annotation type *bbox*
[11/28 12:58:18] d2.evaluation.fast_eval_api INFO: COCOeval_opt.evaluate() finished in 0.02 seconds.
[11/28 12:58:18] d2.evaluation.fast_eval_api INFO: Accumulating evaluation results...
[11/28 12:58:18] d2.evaluation.fast_eval_api INFO: COCOeval_opt.accumulate() finished in 0.01 seconds.
[11/28 12:58:18] d2.evaluation.coco_evaluation INFO: Evaluation results for bbox: 
|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |
|:-----:|:------:|:------:|:-----:|:-----:|:-----:|
| 0.002 | 0.010  | 0.000  | 0.000 | 0.008 | 0.000 |
[11/28 12:58:18] d2.evaluation.coco_evaluation INFO: Per-category bbox AP: 
| category   | AP    | category   | AP    | category   | AP    |
|:-----------|:------|:-----------|:------|:-----------|:------|
| break      | 0.005 | disc       | 0.000 | shadow     | 0.000 |
[11/28 12:58:18] d2.engine.defaults INFO: Evaluation results for val in csv format:
[11/28 12:58:18] d2.evaluation.testing INFO: copypaste: Task: bbox
[11/28 12:58:18] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[11/28 12:58:18] d2.evaluation.testing INFO: copypaste: 0.0016,0.0097,0.0000,0.0000,0.0082,0.0000
[11/28 12:58:41] d2.utils.events INFO:  eta: 0:00:21  iter: 299  total_loss: 0.5874  loss_cls: 0.08463  loss_box_reg: 0.03836  loss_rpn_cls: 0.1726  loss_rpn_loc: 0.2899  validation_loss: 1.168  time: 1.0107  data_time: 0.0545  lr: 9.3444e-05  max_mem: 10405M
[11/28 12:58:46] d2.data.datasets.coco WARNING: 
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[11/28 12:58:46] d2.data.datasets.coco INFO: Loaded 184 images in COCO format from ./dataset/val/labels_val.json
[11/28 12:58:46] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[11/28 12:58:46] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common.NumpySerializedList'>
[11/28 12:58:46] d2.data.common INFO: Serializing 184 elements to byte tensors and concatenating them all ...
[11/28 12:58:46] d2.data.common INFO: Serialized dataset takes 0.07 MiB
[11/28 12:58:46] d2.evaluation.coco_evaluation WARNING: COCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.
[11/28 12:58:46] d2.evaluation.evaluator INFO: Start inference on 184 batches
[11/28 12:58:46] d2.evaluation.evaluator INFO: Inference done 11/184. Dataloading: 0.0007 s/iter. Inference: 0.0333 s/iter. Eval: 0.0003 s/iter. Total: 0.0342 s/iter. ETA=0:00:05
[11/28 12:58:51] d2.evaluation.evaluator INFO: Inference done 153/184. Dataloading: 0.0009 s/iter. Inference: 0.0339 s/iter. Eval: 0.0003 s/iter. Total: 0.0352 s/iter. ETA=0:00:01
[11/28 12:58:52] d2.evaluation.evaluator INFO: Total inference time: 0:00:06.299940 (0.035195 s / iter per device, on 1 devices)
[11/28 12:58:52] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:00:06 (0.033703 s / iter per device, on 1 devices)
[11/28 12:58:52] d2.evaluation.coco_evaluation INFO: Preparing results for COCO format ...
[11/28 12:58:52] d2.evaluation.coco_evaluation INFO: Saving results to ./output/trial-2022-11-28-12-48-57/inference/coco_instances_results.json
[11/28 12:58:52] d2.evaluation.coco_evaluation INFO: Evaluating predictions with unofficial COCO API...
[11/28 12:58:52] d2.evaluation.fast_eval_api INFO: Evaluate annotation type *bbox*
[11/28 12:58:52] d2.evaluation.fast_eval_api INFO: COCOeval_opt.evaluate() finished in 0.02 seconds.
[11/28 12:58:52] d2.evaluation.fast_eval_api INFO: Accumulating evaluation results...
[11/28 12:58:52] d2.evaluation.fast_eval_api INFO: COCOeval_opt.accumulate() finished in 0.01 seconds.
[11/28 12:58:52] d2.evaluation.coco_evaluation INFO: Evaluation results for bbox: 
|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |
|:-----:|:------:|:------:|:-----:|:-----:|:-----:|
| 0.000 | 0.000  | 0.000  | 0.000 | 0.000 | 0.000 |
[11/28 12:58:52] d2.evaluation.coco_evaluation INFO: Per-category bbox AP: 
| category   | AP    | category   | AP    | category   | AP    |
|:-----------|:------|:-----------|:------|:-----------|:------|
| break      | 0.000 | disc       | 0.000 | shadow     | 0.000 |
[11/28 12:58:52] d2.engine.defaults INFO: Evaluation results for val in csv format:
[11/28 12:58:52] d2.evaluation.testing INFO: copypaste: Task: bbox
[11/28 12:58:52] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[11/28 12:58:52] d2.evaluation.testing INFO: copypaste: 0.0000,0.0000,0.0000,0.0000,0.0000,0.0000
[11/28 12:59:19] fvcore.common.checkpoint INFO: Saving checkpoint to ./output/trial-2022-11-28-12-48-57/model_final.pth
[11/28 12:59:29] d2.utils.events INFO:  eta: 0:00:00  iter: 319  total_loss: 0.606  loss_cls: 0.08915  loss_box_reg: 0.04266  loss_rpn_cls: 0.1699  loss_rpn_loc: 0.2918  validation_loss: 1.094  time: 1.0181  data_time: 0.0594  lr: 9.9688e-05  max_mem: 10405M
[11/28 12:59:29] d2.engine.hooks INFO: Overall training speed: 318 iterations in 0:05:23 (1.0181 s / it)
[11/28 12:59:29] d2.engine.hooks INFO: Total training time: 0:10:28 (0:05:05 on hooks)
[11/28 12:59:29] d2.data.datasets.coco WARNING: 
Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.

[11/28 12:59:29] d2.data.datasets.coco INFO: Loaded 184 images in COCO format from ./dataset/val/labels_val.json
[11/28 12:59:29] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[11/28 12:59:29] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common.NumpySerializedList'>
[11/28 12:59:29] d2.data.common INFO: Serializing 184 elements to byte tensors and concatenating them all ...
[11/28 12:59:29] d2.data.common INFO: Serialized dataset takes 0.07 MiB
[11/28 12:59:29] d2.evaluation.coco_evaluation WARNING: COCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.
[11/28 12:59:29] d2.evaluation.evaluator INFO: Start inference on 184 batches
[11/28 12:59:29] d2.evaluation.evaluator INFO: Inference done 11/184. Dataloading: 0.0006 s/iter. Inference: 0.0359 s/iter. Eval: 0.0003 s/iter. Total: 0.0369 s/iter. ETA=0:00:06
[11/28 12:59:34] d2.evaluation.evaluator INFO: Inference done 148/184. Dataloading: 0.0009 s/iter. Inference: 0.0353 s/iter. Eval: 0.0003 s/iter. Total: 0.0366 s/iter. ETA=0:00:01
[11/28 12:59:36] d2.evaluation.evaluator INFO: Total inference time: 0:00:06.543581 (0.036556 s / iter per device, on 1 devices)
[11/28 12:59:36] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:00:06 (0.035094 s / iter per device, on 1 devices)
[11/28 12:59:36] d2.evaluation.coco_evaluation INFO: Preparing results for COCO format ...
[11/28 12:59:36] d2.evaluation.coco_evaluation INFO: Saving results to ./output/trial-2022-11-28-12-48-57/inference/coco_instances_results.json
[11/28 12:59:36] d2.evaluation.coco_evaluation INFO: Evaluating predictions with unofficial COCO API...
[11/28 12:59:36] d2.evaluation.fast_eval_api INFO: Evaluate annotation type *bbox*
[11/28 12:59:36] d2.evaluation.fast_eval_api INFO: COCOeval_opt.evaluate() finished in 0.02 seconds.
[11/28 12:59:36] d2.evaluation.fast_eval_api INFO: Accumulating evaluation results...
[11/28 12:59:36] d2.evaluation.fast_eval_api INFO: COCOeval_opt.accumulate() finished in 0.01 seconds.
[11/28 12:59:36] d2.evaluation.coco_evaluation INFO: Evaluation results for bbox: 
|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |
|:-----:|:------:|:------:|:-----:|:-----:|:-----:|
| 0.018 | 0.169  | 0.000  | 0.000 | 0.005 | 0.028 |
[11/28 12:59:36] d2.evaluation.coco_evaluation INFO: Per-category bbox AP: 
| category   | AP    | category   | AP    | category   | AP    |
|:-----------|:------|:-----------|:------|:-----------|:------|
| break      | 0.006 | disc       | 0.033 | shadow     | 0.017 |
[11/28 12:59:36] d2.engine.defaults INFO: Evaluation results for val in csv format:
[11/28 12:59:36] d2.evaluation.testing INFO: copypaste: Task: bbox
[11/28 12:59:36] d2.evaluation.testing INFO: copypaste: AP,AP50,AP75,APs,APm,APl
[11/28 12:59:36] d2.evaluation.testing INFO: copypaste: 0.0184,0.1687,0.0000,0.0000,0.0049,0.0275
